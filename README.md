````markdown
# ğŸ“ GATE Question Topic Classifier using DistilBERT

This repository contains a fine-tuned **DistilBERT** model for **topic classification of GATE questions**. It uses a labeled dataset of GATE-style questions across multiple subjects and predicts the corresponding topic label.

---

## ğŸš€ Features

- ğŸ” Text classification using **DistilBERT**
- ğŸ§  Trained on GATE question dataset with labeled topics
- ğŸ“Š Evaluation with **Accuracy** and **F1 Score**
- ğŸ§ª Inference-ready model with easy prediction interface
- ğŸ’¾ Model, Tokenizer, and Label Encoder persistence supported

---

## ğŸ§¾ Dataset

The dataset used is a CSV file with the following columns:

- `question` â€” The GATE question text
- `topic` â€” The manually annotated topic label

---

## ğŸ“¦ Requirements

Install the required packages:

```bash
pip install transformers tensorflow scikit-learn pandas
````

---

## ğŸ› ï¸ Training Pipeline

### 1. Preprocessing

* Load CSV data
* Drop rows with missing values
* Encode topic labels using `LabelEncoder`
* Split into train (70%), validation (15%), and test (15%) sets

### 2. Tokenization

Tokenized using `DistilBertTokenizer` with:

* `max_length = 128`
* Padding and truncation

### 3. Model

* Model: `TFDistilBertForSequenceClassification`
* Optimizer: Adam with `learning_rate=2e-5`
* Loss: Sparse Categorical Crossentropy
* Metrics: Sparse Categorical Accuracy

### 4. Training

```python
model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=3
)
```

---

## ğŸ“ˆ Evaluation

After training, the model is evaluated on the test set:

```python
Test Accuracy: 0.9241
Test F1 Score: 0.9182
```

(*Example results, may vary*)

---

## ğŸ” Inference

Use the `predict()` function to classify new GATE questions:

```python
predict([
    "Consider a demand paging memory management system with 32-bit logical address..."
])
```

Returns:

```
['Operating Systems']
```

---

## ğŸ’¾ Saving the Model

The model, tokenizer, and label encoder are saved to disk:

```python
model.save_pretrained(save_dir)
tokenizer.save_pretrained(save_dir)
pickle.dump(label_encoder, open('label_encoder.pkl', 'wb'))
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ questions-topic-classification.ipynb
â”œâ”€â”€ questions-data-new.csv
â”œâ”€â”€ main_model/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ tf_model.h5
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ label_encoder.pkl
```

